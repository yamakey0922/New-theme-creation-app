<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>材料研究開発戦略 AIディスカッション</title>
    <!-- Tailwind CSS CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- marked.js CDN (Markdownパーサー) -->
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <!-- Font Awesome CDN (アイコン) -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    
    <!-- スタイル定義 -->
    <style>
        /* Interフォントの読み込み */
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');
        
        body {
            font-family: 'Inter', 'Noto Sans JP', sans-serif;
        }

        /* カスタムスクロールバー */
        #chat-container::-webkit-scrollbar {
            width: 8px;
        }
        #chat-container::-webkit-scrollbar-track {
            background: #f1f5f9; /* coolGray-100 */
        }
        #chat-container::-webkit-scrollbar-thumb {
            background: #94a3b8; /* coolGray-400 */
            border-radius: 4px;
        }
        #chat-container::-webkit-scrollbar-thumb:hover {
            background: #64748b; /* coolGray-500 */
        }
        
        /* レポートモーダルのスクロールバー */
        #report-content::-webkit-scrollbar {
            width: 6px;
        }
        #report-content::-webkit-scrollbar-track {
            background: #f8fafc; /* coolGray-50 */
        }
        #report-content::-webkit-scrollbar-thumb {
            background: #cbd5e1; /* coolGray-300 */
            border-radius: 3px;
        }

        /* チャットバブルのスタイル */
        .chat-bubble {
            max-width: 80%;
            padding: 0.75rem 1rem;
            border-radius: 1rem;
            margin-bottom: 0.5rem;
            word-wrap: break-word;
        }

        .chat-technician {
            background-color: #3b82f6; /* blue-500 */
            color: white;
            border-bottom-right-radius: 0.25rem;
            align-self: flex-end;
        }

        .chat-chatgpt {
            background-color: #e5e7eb; /* gray-200 */
            color: #1f2937; /* gray-800 */
            border-bottom-left-radius: 0.25rem;
            align-self: flex-start;
        }

        .chat-gemini {
            background-color: #f3e8ff; /* purple-100 */
            color: #1f2937; /* gray-800 */
            border-bottom-left-radius: 0.25rem;
            align-self: flex-start;
        }
        
        /* レポート内のMarkdownスタイル */
        #report-output h1 { font-size: 1.5rem; font-weight: 600; margin-top: 1rem; margin-bottom: 0.5rem; border-bottom: 1px solid #e5e7eb; padding-bottom: 0.25rem; }
        #report-output h2 { font-size: 1.25rem; font-weight: 600; margin-top: 1rem; margin-bottom: 0.5rem; }
        #report-output h3 { font-size: 1.1rem; font-weight: 600; margin-top: 0.75rem; margin-bottom: 0.25rem; }
        #report-output ul { list-style-type: disc; margin-left: 1.5rem; margin-bottom: 0.5rem; }
        #report-output ol { list-style-type: decimal; margin-left: 1.5rem; margin-bottom: 0.5rem; }
        #report-output p { margin-bottom: 0.5rem; }
        #report-output strong { font-weight: 600; }
        #report-output code { background-color: #f3f4f6; padding: 0.1rem 0.25rem; border-radius: 0.25rem; font-family: monospace; }
        
        /* マイクボタンの録音中アニメーション */
        @keyframes pulse {
            0%, 100% {
                opacity: 1;
                transform: scale(1);
            }
            50% {
                opacity: 0.7;
                transform: scale(1.1);
            }
        }
        .recording {
            animation: pulse 1.5s infinite;
            background-color: #ef4444; /* red-500 */
            color: white;
        }
    </style>
</head>
<body class="bg-gray-100 flex flex-col h-screen antialiased">

    <!-- ヘッダー -->
    <header class="bg-white shadow-md w-full p-4 border-b border-gray-200">
        <h1 class="text-xl md:text-2xl font-bold text-gray-800 text-center">
            <i class="fa-solid fa-flask-vial text-blue-500"></i>
            材料研究開発戦略 AIディスカッション
        </h1>
    </header>

    <!-- メインコンテンツ (チャットエリア + 入力エリア) -->
    <main class="flex-1 flex flex-col overflow-hidden p-4 md:p-6 lg:p-8">
        
        <!-- チャットコンテナ -->
        <div id="chat-container" class="flex-1 overflow-y-auto bg-white p-4 md:p-6 rounded-lg shadow-inner border border-gray-200 flex flex-col space-y-4">
            <!-- チャットメッセージがここに追加されます -->
        </div>

        <!-- ローディングインジケーター -->
        <div id="loading-indicator" class="hidden text-center p-4 items-center justify-center space-x-2 text-gray-500">
            <svg class="animate-spin h-5 w-5 text-blue-500" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
            </svg>
            <span>AIが応答を生成中です...</span>
        </div>
        
        <!-- マイクステータス -->
        <div id="mic-status" class="hidden text-center p-2 text-red-500 font-medium">
            <i class="fa-solid fa-microphone-lines animate-pulse"></i> 録音中...
        </div>

        <!-- 入力エリア -->
        <div class="bg-white p-4 md:p-6 mt-4 rounded-lg shadow-md border border-gray-200">
            <div class="flex items-start space-x-2 md:space-x-4">
                <textarea id="message-input" rows="3" class="flex-1 p-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500 resize-none" placeholder="議論したい内容、または『議論終了』と入力してください..."></textarea>
                
                <button id="send-button" title="送信" class="p-3 h-full bg-blue-500 text-white rounded-lg hover:bg-blue-600 focus:outline-none focus:ring-2 focus:ring-blue-500 focus:ring-offset-2 transition-colors disabled:opacity-50 disabled:cursor-not-allowed">
                    <i class="fa-solid fa-paper-plane fa-fw"></i>
                </button>
                
                <button id="mic-button" title="音声入力" class="p-3 h-full bg-gray-600 text-white rounded-lg hover:bg-gray-700 focus:outline-none focus:ring-2 focus:ring-gray-500 focus:ring-offset-2 transition-colors disabled:opacity-50 disabled:cursor-not-allowed">
                    <i id="mic-icon" class="fa-solid fa-microphone fa-fw"></i>
                </button>
            </div>
        </div>
    </main>
    
    <!-- レポート生成モーダル -->
    <div id="report-modal" class="fixed inset-0 bg-gray-800 bg-opacity-75 flex items-center justify-center p-4 z-50 hidden transition-opacity duration-300">
        <div class="bg-white rounded-lg shadow-xl w-full max-w-3xl h-full max-h-[90vh] flex flex-col">
            <!-- モーダルヘッダー -->
            <div class="flex justify-between items-center p-5 border-b border-gray-200">
                <h2 class="text-xl font-semibold text-gray-800">
                    <i class="fa-solid fa-file-alt text-purple-600"></i>
                    戦略サマリーレポート
                </h2>
                <button id="close-report-button" class="text-gray-400 hover:text-gray-600 focus:outline-none">
                    <i class="fa-solid fa-times fa-xl"></i>
                </button>
            </div>
            
            <!-- モーダルコンテンツ -->
            <div id="report-content" class="flex-1 p-6 overflow-y-auto">
                <div id="report-loading" class="text-center py-10">
                    <svg class="animate-spin h-8 w-8 text-purple-600 mx-auto" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                        <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                        <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                    </svg>
                    <p class="mt-4 text-gray-600 font-medium">Geminiが議論を分析し、レポートを作成しています...</p>
                </div>
                <!-- レポート内容がここに挿入されます -->
                <div id="report-output" class="prose max-w-none"></div>
            </div>
            
            <!-- モーダル フッター -->
            <div class="p-4 border-t border-gray-200 bg-gray-50 rounded-b-lg">
                <p class="text-sm text-gray-500 text-center">
                    <i class="fa-solid fa-lightbulb"></i>
                    このレポートはAIによって生成されました。
                </p>
            </div>
        </div>
    </div>


    <!-- JavaScript -->
    <script type="module">
        // ----------------------------------------
        // グローバル変数と設定
        // ----------------------------------------
        const chatContainer = document.getElementById('chat-container');
        const messageInput = document.getElementById('message-input');
        const sendButton = document.getElementById('send-button');
        const micButton = document.getElementById('mic-button');
        const micIcon = document.getElementById('mic-icon');
        const micStatus = document.getElementById('mic-status');
        const loadingIndicator = document.getElementById('loading-indicator');
        
        // レポートモーダル
        const reportModal = document.getElementById('report-modal');
        const closeReportButton = document.getElementById('close-report-button');
        const reportLoading = document.getElementById('report-loading');
        const reportOutput = document.getElementById('report-output');

        // Gemini API設定
        const apiKey = ""; // Canvasが自動的に提供します
        const genAIApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;

        // チャット履歴 (UI表示用とAPI送信用)
        // uiHistory: { speaker: 'Technician' | 'ChatGPT' | 'Gemini', text: string }[]
        let uiHistory = [];
        
        // apiHistory: { role: 'user' | 'model', parts: [{ text: string }] }[]
        // APIの仕様 (user/modelの交互) を守るための履歴
        let apiHistory = [];
        
        let isAIBusy = false; // AIの応答中フラグ
        let isRecording = false; // 録音中フラグ

        // Web Speech API (音声認識) の設定
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;
        
        // ブラウザが音声認識をサポートしているかチェック
        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'ja-JP'; // 言語を日本語に設定
            recognition.interimResults = false; // 途中の結果は不要
            recognition.continuous = false; // 単一の発話
            
            // 音声認識の結果が得られたとき
            recognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                messageInput.value = transcript;
                stopRecording();
            };

            // 音声認識が終了したとき
            recognition.onend = () => {
                if (isRecording) {
                    stopRecording();
                }
            };
            
            // エラーが発生したとき
            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                micStatus.textContent = `エラー: ${event.error}`;
                micStatus.classList.remove('hidden');
                setTimeout(() => micStatus.classList.add('hidden'), 3000);
                stopRecording();
            };

        } else {
            console.warn('Speech Recognition API is not supported in this browser.');
            micButton.disabled = true;
            micButton.title = "お使いのブラウザは音声認識をサポートしていません";
        }

        // ----------------------------------------
        // システムプロンプト (ペルソナ定義)
        // ----------------------------------------
        const systemPromptChatGPT = {
            parts: [{ text: `
あなたは、材料研究開発の「シーズドリブン」担当AIアシスタント「ChatGPT」です。
あなたの役割は以下の通りです。

1.  **先端研究の分析:** 技術者から指定された材料領域について、最新の先端研究、先行研究、科学的エビデンスを収集・分析します。
2.  **研究経緯の整理:** その最新研究に至った経緯や、技術的なブレークスルーのポイントを明確に整理します。
3.  **トピックスの提案:** 技術者が提供する「社内の強み（既存技術、設備、ノウハウ）」を理解し、それを活用できそうな新しい研究トピックスを具体的に提案します。
4.  **議論の促進:** 常に科学的根拠に基づき、シーズ（技術の種）の観点から議論をリードしてください。
`}]
        };

        const systemPromptGemini = {
            parts: [{ text: `
あなたは、材料研究開発の「ニーズドリブン」担当AIアシスタント「Gemini」です。
あなたの役割は以下の通りです。

1.  **将来ニーズの具体化:** 技術者が提示する概念的な将来像やビジョンを深掘りします。
2.  **市場・環境分析:** 世界中の技術ロードマップ、市場動向、自然環境（例：規制、SDGs）、社会環境（例：高齢化、ライフスタイル変化）、地理的状況などを幅広く分析します。
3.  **出口戦略の明確化:** 上記の分析に基づき、開発される技術の具体的な「使われ方」、ターゲットとなる「想定顧客」、そして彼らが抱える「本質的な課題（ニーズ）」を明確にします。
4.  **議論の促進:** 常に市場と顧客の視点に立ち、ニーズ（出口）の観点から議論をリードしてください。
`}]
        };

        const systemPromptReport = {
            parts: [{ text: `
あなたは、優秀な技術戦略コンサルタントです。
あなたの役割は、以下の「技術者」「ChatGPT（シーズ担当）」「Gemini（ニーズ担当）」の三者による議論の全履歴を詳細に分析することです。

分析に基づき、以下の3つのセクションで構成される詳細な「戦略サマリーレポート」を作成してください。

1.  **議論の要約:**
    * 議論全体の流れと、主要な論点を時系列で簡潔にまとめてください。
    * 各参加者（技術者、ChatGPT、Gemini）の重要な貢献や指摘事項を明確にしてください。

2.  **新テーマ・新プロジェクトの提案:**
    * 議論（シーズ、ニーズ、社の強み）から導き出される、具体的かつ実行可能性のある「新研究テーマ」または「新プロジェクト」を複数提案してください。
    * 各提案について、その背景（どの議論に基づいているか）、目的、期待される成果を明確に記述してください。

3.  **これからの進め方（ネクストステップ）:**
    * 提案されたテーマ/プロジェクトを推進するために、明日から取るべき具体的なアクションプランを提案してください。
    * （例：追加の市場調査、特定の先行研究の深掘り、必要なリソース（人材、設備）の特定、初期実験計画の立案など）

レポートは、経営層や研究開発リーダーが意思決定できるように、プロフェッショナルかつ論理的な構成で記述してください。
`}]
        };

        // ----------------------------------------
        // イベントリスナー
        // ----------------------------------------
        
        // ページ読み込み完了時
        window.addEventListener('load', () => {
            // 最初の挨拶メッセージ
            const firstMessage = "技術者の方、こんにちは。私はシーズドリブン担当のChatGPTです。";
            const secondMessage = "私はニーズドリブン担当のGeminiです。本日はどの材料研究開発領域について議論を開始しますか？ 具体的な領域を教えてください。";
            
            addMessageToUI('ChatGPT', firstMessage);
            uiHistory.push({ speaker: 'ChatGPT', text: firstMessage });
            // API履歴には、最初の挨拶はシステムプロンプトの一部として扱うため、ここでは追加しない
            // もしくは、user/modelの対として追加する
            apiHistory.push({ role: 'user', parts: [{ text: "議論を開始してください。" }] });
            apiHistory.push({ role: 'model', parts: [{ text: firstMessage }] });


            setTimeout(() => {
                addMessageToUI('Gemini', secondMessage);
                uiHistory.push({ speaker: 'Gemini', text: secondMessage });
                // 直前のmodelの応答に結合
                apiHistory[apiHistory.length - 1].parts[0].text += `\n\n${secondMessage}`;
            }, 1000); // 少し遅らせて表示
        });

        // 送信ボタン
        sendButton.addEventListener('click', handleUserInput);
        
        // Enterキーで送信 (Shift+Enterで改行)
        messageInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleUserInput();
            }
        });

        // マイクボタン
        micButton.addEventListener('click', () => {
            if (!recognition) return;
            
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        });

        // レポートモーダルを閉じる
        closeReportButton.addEventListener('click', () => {
            reportModal.classList.add('hidden');
        });

        // ----------------------------------------
        // 音声認識ヘルパー
        // ----------------------------------------
        
        function startRecording() {
            if (isAIBusy) return; // AI応答中は録音しない
            try {
                recognition.start();
                isRecording = true;
                micButton.classList.add('recording');
                micIcon.classList.remove('fa-microphone');
                micIcon.classList.add('fa-stop');
                micStatus.textContent = "録音中...";
                micStatus.classList.remove('hidden');
                messageInput.disabled = true;
                sendButton.disabled = true;
            } catch (e) {
                console.error("Recording start error:", e);
                micStatus.textContent = "エラー: 録音を開始できませんでした。";
                micStatus.classList.remove('hidden');
                setTimeout(() => micStatus.classList.add('hidden'), 3000);
            }
        }

        function stopRecording() {
            if (!isRecording) return;
            recognition.stop();
            isRecording = false;
            micButton.classList.remove('recording');
            micIcon.classList.add('fa-microphone');
            micIcon.classList.remove('fa-stop');
            micStatus.classList.add('hidden');
            messageInput.disabled = false;
            sendButton.disabled = false;
        }

        // ----------------------------------------
        // 中核ロジック
        // ----------------------------------------
        
        /**
         * ユーザーの入力を処理
         */
        async function handleUserInput() {
            const message = messageInput.value.trim();
            if (!message || isAIBusy) return;
            
            // UI更新
            addMessageToUI('Technician', message);
            messageInput.value = '';
            setLoading(true);
            
            // 履歴更新
            uiHistory.push({ speaker: 'Technician', text: message });
            
            // API履歴を更新 (user/modelの交互を維持)
            // 直前のmodel (C+G) の応答を受けてのuserの応答
            apiHistory.push({ role: 'user', parts: [{ text: message }] });


            // 終了キーワードのチェック
            const endKeywords = ['議論終了', '議論をおわる', 'おわり', 'レポート作成', '終了します'];
            if (endKeywords.some(keyword => message.includes(keyword))) {
                // 議論終了処理
                await generateReport();
                setLoading(false);
                return;
            }

            // AIの応答チェーンを開始
            try {
                // 1. ChatGPT (シーズ) の応答
                const responseGpt = await callGeminiApi(systemPromptChatGPT, apiHistory, true); // Google Search有効
                addMessageToUI('ChatGPT', responseGpt);
                uiHistory.push({ speaker: 'ChatGPT', text: responseGpt });
                // apiHistoryにmodelの応答として追加
                apiHistory.push({ role: 'model', parts: [{ text: responseGpt }] });

                // 2. Gemini (ニーズ) の応答 (ChatGPTの応答を含む履歴で)
                const responseGemini = await callGeminiApi(systemPromptGemini, apiHistory, true); // Google Search有効
                addMessageToUI('Gemini', responseGemini);
                uiHistory.push({ speaker: 'Gemini', text: responseGemini });
                
                // 直前のmodel (ChatGPT) の応答に、Geminiの応答を追記して結合する
                // これにより、[user(T1), model(C1+G1), user(T2), model(C2+G2)] の形式を維持
                apiHistory[apiHistory.length - 1].parts[0].text += `\n\n${responseGemini}`;

            } catch (error) {
                console.error("AI response chain error:", error);
                addMessageToUI('System', `エラーが発生しました: ${error.message}`);
            } finally {
                setLoading(false);
            }
        }

        /**
         * レポートを生成
         */
        async function generateReport() {
            console.log("Generating report...");
            reportModal.classList.remove('hidden');
            reportLoading.classList.remove('hidden');
            reportOutput.innerHTML = '';

            try {
                // レポート作成用のAPI履歴を作成
                // apiHistoryには [user, model, user, model...] が入っている
                // これをそのまま渡す
                
                // 最後の「議論終了」というuserメッセージはレポート生成には不要な場合があるので、除く
                // ただし、その直前のmodelの応答は必要
                // apiHistoryの最後の要素が "user" (終了メッセージ) なら、それを除いた履歴を使う
                let reportHistory = [...apiHistory];
                if (reportHistory.length > 0 && reportHistory[reportHistory.length - 1].role === 'user') {
                     // 最後のuserメッセージを除き、その前のmodelまでの履歴を使う
                     // ただし、最初の挨拶 [user, model] の後、[user(T1), model(C1+G1)] と続くため、
                     // 履歴が [..., user(T_end)] で終わっているはず。
                     // reportHistory.pop(); // これでOK
                }
                
                // 最後の「議論終了」という発言は、レポート作成のトリガーであって、
                // 分析対象の議論内容そのものではない。
                // したがって、apiHistoryの最後の user メッセージを除外してAPIに渡す
                
                let historyForReport = [...apiHistory];
                if(historyForReport.length > 0 && historyForReport[historyForReport.length - 1].role === 'user') {
                    historyForReport.pop();
                }

                const reportText = await callGeminiApi(systemPromptReport, historyForReport, false); // レポート作成時はSearch不要
                
                // MarkdownをHTMLに変換して表示
                reportOutput.innerHTML = marked.parse(reportText);
                reportLoading.classList.add('hidden');

            } catch (error) {
                console.error("Report generation error:", error);
                reportOutput.innerHTML = `<p class="text-red-500">レポートの生成中にエラーが発生しました: ${error.message}</p>`;
                reportLoading.classList.add('hidden');
            }
        }

        /**
         * Gemini API 呼び出し (Exponential Backoff 付き)
         * @param {object} systemInstruction - システムプロンプト
         * @param {array} history - API用のチャット履歴
         * @param {boolean} useGoogleSearch - Google Search を使うか
         */
        async function callGeminiApi(systemInstruction, history, useGoogleSearch = false) {
            const maxRetries = 5;
            let delay = 1000; // 1秒から開始

            // historyが user/model の交互で終わっていることを確認
            // もし末尾が user なら OK
            // もし末尾が model なら OK
            // もし空なら OK
            // APIは最後の model の次が user であることを期待する
            // APIは最後の user の次が model であることを期待する
            
            // このアプリのロジックでは、Cを呼ぶときは末尾が user(T)
            // Gを呼ぶときは末尾が model(C)
            // レポートを呼ぶときは末尾が user(T_end) または model(C+G)
            
            // Gemini APIは、末尾が model であっても、次の user プロンプトを期待するのではなく、
            // history全体 + 新規の user プロンプト を渡すのが一般的。
            // しかし、チャット (generateContent) では、history を渡せば文脈を理解する。
            
            //
            // **重要**: Gemini APIの `generateContent` (非ストリーミング) は、`contents` (履歴) を渡す。
            // `contents` の最後の `role` は、APIが応答すべき `role` (つまり `model`) の *反対* (つまり `user`) である必要がある。
            //
            // このアプリのロジックを修正：
            // 1. handleUserInput: apiHistory.push(user)
            // 2. callGpt: callGeminiApi(systemGpt, apiHistory)
            //    - この時点で apiHistory の末尾は user(T)
            //    - 応答(C)を受け取り、apiHistory.push(model(C))
            // 3. callGemini: callGeminiApi(systemGemini, apiHistory)
            //    - この時点で apiHistory の末尾は model(C)
            //    - **これではAPIがエラーになる**
            //
            // **解決策**:
            // `callGeminiApi` に渡す履歴は、必ず `role: 'user'` で終わるように調整する。
            //
            // 修正後のフロー:
            // 1. handleUserInput:
            //    apiHistory.push({ role: 'user', parts: [{ text: message }] }); // T1
            // 2. ChatGPT(S) 呼び出し:
            //    const responseGpt = await callGeminiApi(systemPromptChatGPT, apiHistory, true);
            //    apiHistory.push({ role: 'model', parts: [{ text: responseGpt }] }); // C1
            // 3. Gemini(N) 呼び出し:
            //    // Gを呼ぶために、Cの応答を「観測」した user としてのダミープロンプトを追加
            //    const promptForGemini = { 
            //        role: 'user', 
            //        parts: [{ text: "（Geminiさん、今のChatGPTの意見を受けて、ニーズの観点からどう思いますか？）" }] 
            //    };
            //    const historyForGemini = [...apiHistory, promptForGemini];
            //    const responseGemini = await callGeminiApi(systemPromptGemini, historyForGemini, true);
            //    // apiHistoryには「ダミープロンプト」と「Gの応答」を追加
            //    apiHistory.push(promptForGemini);
            //    apiHistory.push({ role: 'model', parts: [{ text: responseGemini }] }); // G1
            //
            // これだと `uiHistory` と `apiHistory` が乖離しすぎる。
            //
            // **再採用（前述の「クリーンな方法」）**
            // 1. handleUserInput:
            //    apiHistory.push({ role: 'user', parts: [{ text: message }] }); // T1
            // 2. ChatGPT(S) 呼び出し:
            //    const responseGpt = await callGeminiApi(systemPromptChatGPT, apiHistory, true);
            //    apiHistory.push({ role: 'model', parts: [{ text: responseGpt }] }); // C1
            // 3. Gemini(N) 呼び出し:
            //    const responseGemini = await callGeminiApi(systemPromptGemini, apiHistory, true);
            //    // Gの応答を、直前のCの応答 (model) に「結合」する
            //    apiHistory[apiHistory.length - 1].parts[0].text += `\n\n${responseGemini}`; // C1 + G1
            //
            // **この方法の懸念:** Gを呼び出すとき、`apiHistory` の末尾が `model(C1)` になっている。
            // Gemini APIはこれを許容するか？
            //
            // ドキュメント確認...
            // "When building a multi-turn conversation (like chat), provide a history of the conversation... The last part of the Contents array must be from the 'user' role."
            //
            // **ダメだ。最後のroleは 'user' でなければならない。**
            //
            //
            // **最終決定ロジック (前述の「最もクリーンな方法」のバリエーション)**
            // Gを呼ぶとき、Cの応答を `user` メッセージとして「引用」する。
            //
            // 1. handleUserInput:
            //    const userMessage = { role: 'user', parts: [{ text: message }] }; // T1
            //    apiHistory.push(userMessage);
            //
            // 2. ChatGPT(S) 呼び出し:
            //    const responseGptText = await callGeminiApi(systemPromptChatGPT, apiHistory, true);
            //    const gptMessage = { role: 'model', parts: [{ text: responseGptText }] }; // C1
            //    apiHistory.push(gptMessage);
            //    addMessageToUI('ChatGPT', responseGptText);
            //
            // 3. Gemini(N) 呼び出し:
            //    // Cの応答を引用し、Gに意見を求めるための「新しい user プロンプト」を作成
            //    const promptForGemini = {
            //        role: 'user',
            //        parts: [{ text: `ChatGPTがシーズの観点から以下のように述べました。\n\n「${responseGptText}」\n\nこれを受けて、Geminiさん、ニーズドリブンの観点からあなたの分析と意見を聞かせてください。` }]
            //    };
            //    
            //    // apiHistory にこの「中間プロンプト」を追加
            //    apiHistory.push(promptForGemini);
            //    // UIにはこの中間プロンプトは *表示しない*
            //
            //    const responseGeminiText = await callGeminiApi(systemPromptGemini, apiHistory, true);
            //    const geminiMessage = { role: 'model', parts: [{ text: responseGeminiText }] }; // G1
            //    apiHistory.push(geminiMessage);
            //    addMessageToUI('Gemini', responseGeminiText);
            //
            // このロジックで `callGeminiApi` を実装する。
            
            // `history` (apiHistory) は、この関数が呼ばれる時点で `user` で終わっているか、`model` で終わっているか...
            // 呼び出し元 (handleUserInput) でロジックを確定させる。
            // この関数 `callGeminiApi` は、渡された history をそのまま使う。
            
            
            // **** (元のロジックに戻る) ****
            // handleUserInput 内で、`apiHistory` が `user` で終わっていることを保証して C を呼び出す。
            // C の応答 (model) を `apiHistory` に追加。
            // G を呼ぶために、`apiHistory` (末尾 model) に、Gへのプロンプト (user) を追加する。
            
            // *** `handleUserInput` 内のロジックを修正 *** (上記参照)
            // この `callGeminiApi` は、渡された履歴 (末尾が `user` であることが保証されている) を使うだけ。


            const payload = {
                contents: history,
                systemInstruction: systemInstruction,
                generationConfig: {
                    temperature: 0.7,
                    topK: 40,
                    topP: 0.95,
                    maxOutputTokens: 8192,
                }
            };

            if (useGoogleSearch) {
                payload.tools = [{ "google_search": {} }];
            }

            for (let i = 0; i < maxRetries; i++) {
                try {
                    const response = await fetch(genAIApiUrl, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(payload)
                    });

                    if (!response.ok) {
                        throw new Error(`API request failed with status ${response.status}: ${await response.text()}`);
                    }

                    const result = await response.json();
                    
                    if (result.candidates && result.candidates[0].content?.parts?.[0]?.text) {
                        return result.candidates[0].content.parts[0].text;
                    } else if (result.candidates && result.candidates[0].finishReason === "SAFETY") {
                        throw new Error("応答が安全性の設定によりブロックされました。");
                    } else {
                        console.warn("API response structure unexpected:", result);
                        throw new Error("AIからの有効な応答がありませんでした。");
                    }
                } catch (error) {
                    console.warn(`Attempt ${i + 1} failed: ${error.message}`);
                    if (i === maxRetries - 1) {
                        throw error; // 最終試行でも失敗
                    }
                    await new Promise(resolve => setTimeout(resolve, delay));
                    delay *= 2; // バックオフ時間を倍増
                }
            }
        }

        // ----------------------------------------
        // UI ヘルパー
        // ----------------------------------------

        /**
         * チャットUIにメッセージを追加
         * @param {'Technician' | 'ChatGPT' | 'Gemini' | 'System'} speaker
         * @param {string} message
         */
        function addMessageToUI(speaker, message) {
            const messageElement = document.createElement('div');
            messageElement.classList.add('chat-bubble', 'flex', 'flex-col');
            
            let speakerLabel = '';
            let iconClass = '';
            let bubbleClass = '';

            switch (speaker) {
                case 'Technician':
                    bubbleClass = 'chat-technician';
                    speakerLabel = '技術者 (あなた)';
                    iconClass = 'fa-solid fa-user';
                    break;
                case 'ChatGPT':
                    bubbleClass = 'chat-chatgpt';
                    speakerLabel = 'ChatGPT (シーズ)';
                    iconClass = 'fa-solid fa-brain text-green-600';
                    break;
                case 'Gemini':
                    bubbleClass = 'chat-gemini';
                    speakerLabel = 'Gemini (ニーズ)';
                    iconClass = 'fa-solid fa-globe text-purple-600';
                    break;
                case 'System':
                    bubbleClass = 'chat-chatgpt'; // システムメッセージはChatGPT風に
                    speakerLabel = 'システム';
                    iconClass = 'fa-solid fa-exclamation-circle text-red-500';
                    break;
            }
            
            messageElement.classList.add(bubbleClass);

            // スピーカーラベルとアイコン
            const speakerElement = document.createElement('div');
            speakerElement.classList.add('flex', 'items-center', 'space-x-2', 'mb-2', 'font-semibold', 'text-sm');
            if (speaker === 'Technician') {
                 speakerElement.classList.add('text-blue-100');
            } else {
                 speakerElement.classList.add('text-gray-700');
            }

            speakerElement.innerHTML = `<i class="${iconClass}"></i><span>${speakerLabel}</span>`;
            
            // メッセージ本文 (Markdownパース)
            const contentElement = document.createElement('div');
            contentElement.classList.add('message-content');
            // XSS対策のため、marked.jsのsanitizeオプションはデフォルト(false)だが、
            // この環境では信頼できるAPIからの応答のみを想定する。
            // 本番環境ではDOMPurifyなどでのサニタイズが推奨される。
            contentElement.innerHTML = marked.parse(message);
            
            messageElement.appendChild(speakerElement);
            messageElement.appendChild(contentElement);
            chatContainer.appendChild(messageElement);

            // 一番下にスクロール
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        /**
         * ローディング状態の設定
         * @param {boolean} isLoading
         */
        function setLoading(isLoading) {
            isAIBusy = isLoading;
            if (isLoading) {
                loadingIndicator.classList.remove('hidden');
                loadingIndicator.classList.add('flex');
                sendButton.disabled = true;
                micButton.disabled = true;
                messageInput.disabled = true;
            } else {
                loadingIndicator.classList.add('hidden');
                loadingIndicator.classList.remove('flex');
                sendButton.disabled = false;
                micButton.disabled = (recognition === undefined); // 音声認識がサポートされていれば有効化
                messageInput.disabled = false;
                messageInput.focus();
            }
        }

    </script>
</body>
</html>